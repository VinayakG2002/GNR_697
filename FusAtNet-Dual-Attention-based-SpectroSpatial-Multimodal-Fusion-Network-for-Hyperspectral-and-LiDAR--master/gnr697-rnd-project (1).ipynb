{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8246092,"sourceType":"datasetVersion","datasetId":4892269}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import relevant libraries\n\nimport scipy.io as sio\nimport numpy as np\nimport tqdm\n\n# The code takes the entire hsi/lidar image as input for 'X' and grounttruth file as input for 'y'\n# and the patchsize as for 'windowSize'.\n# The output are the patches centered around the groundtruth pixel, the corresponding groundtruth label and the\n# pixel location of the patch.\n\ndef make_patches(X, y, windowSize):\n\n  shapeX = np.shape(X)\n\n  margin = int((windowSize-1)/2)\n  newX = np.zeros([shapeX[0]+2*margin,shapeX[1]+2*margin,shapeX[2]])\n\n  newX[margin:shapeX[0]+margin:,margin:shapeX[1]+margin,:] = X\n\n  index = np.empty([0,3], dtype = 'int')\n\n  cou = 0\n  for k in tqdm.tqdm(range(1,np.size(np.unique(y)))):\n    for i in range(shapeX[0]):\n      for j in range(shapeX[1]):\n        if y[i,j] == k:\n          index = np.append(index,np.expand_dims(np.array([k,i,j]),0),0)\n          #print(cou)\n          cou = cou+1\n\n  patchesX = np.empty([index.shape[0],2*margin+1,2*margin+1,shapeX[2]], dtype = 'float32')\n  patchesY = np.empty([index.shape[0]],dtype = 'uint8')\n\n  for i in range(index.shape[0]):\n    p = index[i,1]\n    q = index[i,2]\n    patchesX[i,:,:,:] = newX[p:p+windowSize,q:q+windowSize,:]\n    patchesY[i] = index[i,0]\n\n  return patchesX, patchesY, index\n\n# Reading data\ndata = sio.loadmat('/kaggle/input/houston/houston_data.mat')\n\n# Concatenating HSI and LiDAR bands from the data and removing spurious pixels\nfeats = np.concatenate([data['hsi'], np.expand_dims(data['lidar'], axis = 2)], axis = 2)\n\n# Normalising the bands using min-max normalization \n\nfeats_norm = np.empty([349,1905,145], dtype = 'float32')\nfor i in tqdm.tqdm(range(145)):\n  feats_norm[:,:,i] = feats[:,:,i]-np.min(feats[:,:,i])\n  feats_norm[:,:,i] = feats_norm[:,:,i]/np.max(feats_norm[:,:,i])\n\n## REading train and test groundtruth images\n\ntrain = data['train']\ntest = data['test']\n\n# Create train patches\ntrain_patches, train_labels, index_train = make_patches(feats_norm, train, 11)\n\n# Create test patches\ntest_patches, test_labels, index_test = make_patches(feats_norm, test, 11)\n\n# Data augmentation by rotating patches by 90, 180 and 270 degrees\n\ntr90 = np.empty([2832,11,11,145], dtype = 'float32')\ntr180 = np.empty([2832,11,11,145], dtype = 'float32')\ntr270 = np.empty([2832,11,11,145], dtype = 'float32')\n\nfor i in tqdm.tqdm(range(2832)):\n  tr90[i,:,:,:] = np.rot90(train_patches[i,:,:,:])\n  tr180[i,:,:,:] = np.rot90(tr90[i,:,:,:])\n  tr270[i,:,:,:] = np.rot90(tr180[i,:,:,:])\n\ntrain_patches = np.concatenate([train_patches, tr90, tr180, tr270], axis = 0)\ntrain_labels = np.concatenate([train_labels,train_labels,train_labels,train_labels], axis = 0)\n\n# Save the train patches/ test patches along with the labels\nimport os\nimport numpy as np\n\n# Create directory if it doesn't exist\noutput_dir = '/kaggle/working/Houston/'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\n# Save the normalised HSI and LiDAR images\nnp.save(os.path.join(output_dir, 'hsi.npy'), feats_norm[:, :, 0:144])\nnp.save(os.path.join(output_dir, 'lidar.npy'), feats_norm[:, :, 144:])\n\nnp.save('/kaggle/working/train_patches',train_patches)\nnp.save('/kaggle/working/test_patches',test_patches)\nnp.save('/kaggle/working/train_labels',train_labels)\nnp.save('/kaggle/working/test_labels',test_labels)\n\n# Save the normalised HSI and LiDAR images\n\nnp.save('/kaggle/working/Houston/hsi',feats_norm[:,:,0:144])\nnp.save('/kaggle/working/Houston/lidar',feats_norm[:,:,144])","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:31:47.508061Z","iopub.execute_input":"2024-04-29T20:31:47.508607Z","iopub.status.idle":"2024-04-29T20:32:45.220939Z","shell.execute_reply.started":"2024-04-29T20:31:47.508569Z","shell.execute_reply":"2024-04-29T20:32:45.219848Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"100%|██████████| 145/145 [00:05<00:00, 27.51it/s]\n100%|██████████| 15/15 [00:18<00:00,  1.20s/it]\n100%|██████████| 15/15 [00:18<00:00,  1.22s/it]\n100%|██████████| 2832/2832 [00:00<00:00, 8953.33it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tensorflow==2.8","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:32:45.222656Z","iopub.execute_input":"2024-04-29T20:32:45.222991Z","iopub.status.idle":"2024-04-29T20:34:10.720391Z","shell.execute_reply.started":"2024-04-29T20:32:45.222961Z","shell.execute_reply":"2024-04-29T20:34:10.718854Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting tensorflow==2.8\n  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl.metadata (2.9 kB)\nRequirement already satisfied: absl-py>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (1.6.3)\nRequirement already satisfied: flatbuffers>=1.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (23.5.26)\nRequirement already satisfied: gast>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (3.10.0)\nCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.8)\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: libclang>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (16.0.6)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (3.3.0)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (4.9.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (1.14.1)\nCollecting tensorboard<2.9,>=2.8 (from tensorflow==2.8)\n  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\nCollecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8)\n  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl.metadata (1.2 kB)\nCollecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8)\n  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.8) (1.60.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.8) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.26.1)\nCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8)\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (2.31.0)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8)\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\nCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8)\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8) (3.0.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8) (3.2.2)\nDownloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m759.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tf-estimator-nightly, tensorboard-plugin-wit, keras, tensorboard-data-server, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n  Attempting uninstall: keras\n    Found existing installation: keras 3.2.1\n    Uninstalling keras-3.2.1:\n      Successfully uninstalled keras-3.2.1\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.7.2\n    Uninstalling tensorboard-data-server-0.7.2:\n      Successfully uninstalled tensorboard-data-server-0.7.2\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.0\n    Uninstalling google-auth-oauthlib-1.2.0:\n      Successfully uninstalled google-auth-oauthlib-1.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.15.1\n    Uninstalling tensorboard-2.15.1:\n      Successfully uninstalled tensorboard-2.15.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.15.0\n    Uninstalling tensorflow-2.15.0:\n      Successfully uninstalled tensorflow-2.15.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow-decision-forests 1.8.1 requires tensorflow~=2.15.0, but you have tensorflow 2.8.0 which is incompatible.\ntensorflow-serving-api 2.14.1 requires tensorflow<3,>=2.14.1, but you have tensorflow 2.8.0 which is incompatible.\ntensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.8.0 which is incompatible.\ntf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Original Architecture**","metadata":{}},{"cell_type":"code","source":"# Import all the necessary libraries and classes\n\nimport numpy as np\nimport tensorflow as tf\nkeras = tf.keras\nfrom keras import backend as K\nfrom keras.layers import Input\nfrom keras.layers import Conv2D, Reshape, BatchNormalization\nfrom keras.layers import Concatenate\nfrom keras.layers import Multiply, GlobalAveragePooling2D, MaxPooling2D\nfrom keras.models import Model\nfrom sklearn.metrics import confusion_matrix\nfrom keras import regularizers\n\n# Function to perform one hot encoding of the class labels \n\ndef my_ohc(lab_arr):\n    lab_arr_unique =  np.unique(lab_arr)\n    r,c = lab_arr.shape\n    r_u  = lab_arr_unique.shape\n    \n    one_hot_enc = np.zeros((r,r_u[0]), dtype = 'float')\n    \n    for i in range(r):\n        for j in range(r_u[0]):\n            if lab_arr[i,0] == lab_arr_unique[j]:\n                one_hot_enc[i,j] = 1\n    \n    return one_hot_enc\n\n# Function that takes the confusion matrix as input and\n# calculates the overall accuracy, producer's accuracy, user's accuracy,\n# Cohen's kappa coefficient and syandard deviation of \n# Cohen's kappa coefficient\n\ndef accuracies(cm):\n  import numpy as np\n  num_class = np.shape(cm)[0]\n  n = np.sum(cm)\n\n  P = cm/n\n  ovr_acc = np.trace(P)\n\n  p_plus_j = np.sum(P, axis = 0)\n  p_i_plus = np.sum(P, axis = 1)\n\n  usr_acc = np.diagonal(P)/p_i_plus\n  prod_acc = np.diagonal(P)/p_plus_j\n\n  theta1 = np.trace(P)\n  theta2 = np.sum(p_plus_j*p_i_plus)\n  theta3 = np.sum(np.diagonal(P)*(p_plus_j + p_i_plus))\n  theta4 = 0\n  for i in range(num_class):\n    for j in range(num_class):\n      theta4 = theta4+P[i,j]*(p_plus_j[i]+p_i_plus[j])**2\n\n  kappa = (theta1-theta2)/(1-theta2)\n\n  t1 = theta1*(1-theta1)/(1-theta2)**2\n  t2 = 2*(1-theta1)*(2*theta1*theta2-theta3)/(1-theta2)**3\n  t3 = ((1-theta1)**2)*(theta4 - 4*theta2**2)/(1-theta2)**4\n\n  s_sqr = (t1+t2+t3)/n\n\n  return ovr_acc, usr_acc, prod_acc, kappa, s_sqr\n\n# This is the main feature extractor for the hyperpsectral images. \n# The input is a hyperspectral patch. It consists of 6 sets of \n# convolutional, relu and batch normalization operations \n\ndef hs(x):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'conv31')(x)\n\n  conv1 = BatchNormalization()(conv1)\n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'conv32')(conv1)\n\n  conv2 = BatchNormalization()(conv2) \n  \n\n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'conv33')(conv2) \n\n  conv3 = BatchNormalization()(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'conv34')(conv3) \n\n  conv4 = BatchNormalization()(conv4)\n\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'conv35')(conv4) \n\n  conv5 = BatchNormalization()(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'conv36')(conv5) \n\n  conv6 = BatchNormalization()(conv6)\n\n  return conv6\n\n# This is the spectral attention mask for hyperspecral images.\n# The input are hyperspectral patches and output is an attention vector \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block and 2D maxpool operation after second and fourth \n# convolution layers. Last convolution layer is followed by a maxpool and \n# Global average pool operation.\n\ndef mask_spec(x):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convc1')(x)\n\n  conv1 = BatchNormalization(name = 'BNc1')(conv1)\n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01),  name = 'convc2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNc2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n  \n  mp1 = MaxPooling2D(pool_size=(2, 2), padding='valid')(res1)\n\n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc3')(mp1) \n\n  conv3 = BatchNormalization(name = 'BNc3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNc4')(conv4)\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n  \n  mp2 = MaxPooling2D(pool_size=(2, 2), padding='valid')(res2)\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc5')(mp2) \n\n  conv5 = BatchNormalization(name = 'BNc5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BNc6')(conv6)\n\n  mp3 = MaxPooling2D(pool_size=(2, 2), padding='valid')(conv6)\n  gap1 = GlobalAveragePooling2D()(mp3)\n\n  return gap1\n\n# This is the spatial attention mask for hyperspecral images.\n# The input are lidar patches and output is an attention tensor \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block after second and fourth \n# convolution layers. \n\ndef mask_spat(x):\n  \n  conv1 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convt1')(x)\n\n  conv1 = BatchNormalization(name = 'BNt1')(conv1)\n\n  conv2 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01),  name = 'convt2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNt2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n\n  conv3 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt3')(res1) \n\n  conv3 = BatchNormalization(name = 'BNt3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNt4')(conv4)\n\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt5')(res2) \n\n  conv5 = BatchNormalization(name = 'BNt5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BNt6')(conv6)\n\n  return conv6\n\n# It is a part of modality attention module.  \n# The input are highlighted spectral and spatial attention features from above modules. \n# It consists of 6 convolutional, relu and batch normalization operations. \n\ndef main2(x):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convm31')(x)\n\n  conv1 = BatchNormalization()(conv1)\n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm32')(conv1)\n\n  conv2 = BatchNormalization()(conv2) \n\n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm33')(conv2) \n\n  conv3 = BatchNormalization()(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm34')(conv3) \n\n  conv4 = BatchNormalization()(conv4)\n  \n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm35')(conv4) \n\n  conv5 = BatchNormalization()(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm36')(conv5) \n\n  conv6 = BatchNormalization()(conv6)\n\n  return conv6\n\n# This is the attention layer for maodality attention module. \n# The input are highlighted spectral and spatial attention features from above modules. \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block after second and fourth \n# convolution layers. \n\ndef att2(x):\n  \n  conv1 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convatt1')(x)\n\n  conv1 = BatchNormalization(name = 'BN2t1')(conv1)\n\n  conv2 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BN2t2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n\n  conv3 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt3')(res1) \n\n  conv3 = BatchNormalization(name = 'BN2t3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BN2t4')(conv4)\n\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt5')(res2) \n\n  conv5 = BatchNormalization(name = 'BN2t5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BN2t6')(conv6)\n\n  return conv6\n\n# This is a classifier function. It is a CNN with 6 layers\n# (convolution + RelU + Batch Normalization). Inputs are \n# Attention assisted enhanced features from modality attention module \n# and number of classes\n\ndef clf(x, num_classes):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convcl1')(x)\n\n  conv1 = BatchNormalization(name = 'BNcl1')(conv1)\n  \n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNcl2')(conv2) \n  \n  \n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl3')(conv2) \n\n  conv3 = BatchNormalization(name = 'BNcl3')(conv3)\n  \n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNcl4')(conv4)\n  \n  conv5 = Conv2D(1024, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl5')(conv4) \n\n  conv5 = BatchNormalization(name = 'BNcl5')(conv5)\n\n  conv6 = Conv2D(num_classes, (1,1), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='softmax', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl6')(conv5) \n  \n\n  return Reshape([num_classes])(conv6)\n\n# reading training and test data\n\n\ntrain_patches = np.load('/kaggle/working/train_patches.npy')\ntest_patches = np.load('/kaggle/working/test_patches.npy')\n\ntrain_labels = np.load('/kaggle/working/train_labels.npy')\ntest_labels = np.load('/kaggle/working/test_labels.npy')\n\n# Separating HSI and lidar patches from training\n# validation and testing data\n\n#num_hsi_bands = 144\n#num_lidar_bands = 1\n\ntrain_hsi = train_patches[:,:,:,0:144]\ntrain_lidar = np.expand_dims(train_patches[:,:,:,144], axis = 3) # Expanding dimension to preserve shape\n                                                           #since only one band is present\n\ntest_hsi = test_patches[:,:,:,0:144]\ntest_lidar = np.expand_dims(test_patches[:,:,:,144], axis = 3)\n\n## Training module\n\nK.clear_session()\ng = tf.Graph()\n\nk = 0        #k is created to temporarily store the maximum validation accuracy for each epoch\n\nwith g.as_default():\n\n  x1 = Input(shape=(11,11,144), name='inputA')     #num_hsi_bands = 144\n\n  x2 = Input(shape=(11,11,1), name='inputB')      #num_lidar_bands = 1\n\n  feats_new = hs(x1)                              # Main feature extraction\n\n  # Generating spectral attention mask and spectrally highlighting HSI features\n  spec = Multiply()([feats_new, mask_spec(x1)])   \n  \n  # Generating spatial attention mask  and spatially highlighting HSI features\n  spat = Multiply()([feats_new, mask_spat(x2)]) \n\n  # Concatenationg highlighted features and input features  \n  conc = Concatenate(axis = 3)([x1,x2,spec,spat]) \n\n  feats2 = main2(conc)                            # Modality features extraction\n  mask2 = att2(conc)                              # Modality attention mask\n\n  # Highlighting modality features using modality attention mask\n\n  at_feats = Multiply()([feats2, mask2])  \n\n  clsf = clf(at_feats, 15)                        # Classifier with number of classes = 15\n\n  # Initialising model\n  model_att = Model([x1,x2], clsf, name = 'att_clf')\n\n  # Adam with Nesterov Momentum optimizer\n  optim = keras.optimizers.Nadam(0.00002, beta_1=0.9, beta_2=0.999)\n  \n  # Compiling the model\n  model_att.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n\n  for epoch in range(5):  # Number of epochs = 1000\n    \n    model_att.fit(x = [train_hsi, train_lidar], \n                  y = my_ohc(np.expand_dims(train_labels, axis = 1)),\n                  epochs=1, batch_size = 64, verbose = 1)\n    \n    preds2 = model_att.predict([test_hsi, test_lidar], verbose = 1)\n\n    conf = confusion_matrix(test_labels, np.argmax(preds2,1)) # Test set predictions\n    ovr_acc, _, _, _, _ = accuracies(conf)\n\n    if ovr_acc>=k:\n\n      # Saving model for maximum accuracy     \n      model_att.save('/kaggle/working/Houston/models/model')\n      k = ovr_acc\n      ep = epoch\n    print('acc_max_val = ', np.round(100*k,2), '% at epoch', ep) # Maximum test accuracy\n\n\n# Evaluating the model on test set\n\nK.clear_session()\ng = tf.Graph()\n\nwith g.as_default():\n\n  # Loading saved model\n  model = keras.models.load_model('/kaggle/working/Houston/models/model')\n\n  preds_final = model.predict([test_hsi, test_lidar], verbose = 1)\n  conf_final = confusion_matrix(test_labels, np.argmax(preds_final,1))\n  ovr_acc_final, usr_acc, prod_acc, kappa, s_sqr = accuracies(conf_final)\n\nprint('Test accuracy is ', np.round(100*ovr_acc_final,2), '%') # Final test accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-28T18:19:44.277714Z","iopub.execute_input":"2024-04-28T18:19:44.278014Z","iopub.status.idle":"2024-04-28T21:33:23.462736Z","shell.execute_reply.started":"2024-04-28T18:19:44.277986Z","shell.execute_reply":"2024-04-28T21:33:23.461781Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Train on 11328 samples\n11328/11328 [==============================] - 1861s 164ms/sample - loss: 97.4070 - accuracy: 0.2910\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n  updates=self.state_updates,\n/tmp/ipykernel_34/1166340305.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"acc_max_val =  2.34 % at epoch 0\nTrain on 11328 samples\n11328/11328 [==============================] - 1885s 166ms/sample - loss: 95.8147 - accuracy: 0.6054\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/1166340305.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"acc_max_val =  7.99 % at epoch 1\nTrain on 11328 samples\n11328/11328 [==============================] - 1861s 164ms/sample - loss: 94.6193 - accuracy: 0.7948\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/1166340305.py:47: RuntimeWarning: invalid value encountered in divide\n  usr_acc = np.diagonal(P)/p_i_plus\n/tmp/ipykernel_34/1166340305.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"acc_max_val =  15.04 % at epoch 2\nTrain on 11328 samples\n11328/11328 [==============================] - 1875s 166ms/sample - loss: 93.6500 - accuracy: 0.8948\nacc_max_val =  15.04 % at epoch 2\nTrain on 11328 samples\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/1166340305.py:47: RuntimeWarning: invalid value encountered in divide\n  usr_acc = np.diagonal(P)/p_i_plus\n/tmp/ipykernel_34/1166340305.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"11328/11328 [==============================] - 1947s 172ms/sample - loss: 92.7822 - accuracy: 0.9386\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/1166340305.py:47: RuntimeWarning: invalid value encountered in divide\n  usr_acc = np.diagonal(P)/p_i_plus\n/tmp/ipykernel_34/1166340305.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"acc_max_val =  15.04 % at epoch 2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n  updates=self.state_updates,\n","output_type":"stream"},{"name":"stdout","text":"Test accuracy is  15.04 %\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/1166340305.py:47: RuntimeWarning: invalid value encountered in divide\n  usr_acc = np.diagonal(P)/p_i_plus\n/tmp/ipykernel_34/1166340305.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Used four Atrous Spatial Pyramid Pooling (ASPP)layers with dilation rates of 1,6,12 and 18","metadata":{}},{"cell_type":"code","source":"# Import all the necessary libraries and classes\n\nimport numpy as np\nimport tensorflow as tf\nkeras = tf.keras\nfrom keras import backend as K\nfrom keras.layers import Input\nfrom keras.layers import Conv2D, Reshape, BatchNormalization\nfrom keras.layers import Concatenate\nfrom keras.layers import Multiply, GlobalAveragePooling2D, MaxPooling2D\nfrom keras.models import Model\nfrom sklearn.metrics import confusion_matrix\nfrom keras import regularizers\n\n# Function to perform one hot encoding of the class labels \n\ndef my_ohc(lab_arr):\n    lab_arr_unique =  np.unique(lab_arr)\n    r,c = lab_arr.shape\n    r_u  = lab_arr_unique.shape\n    \n    one_hot_enc = np.zeros((r,r_u[0]), dtype = 'float')\n    \n    for i in range(r):\n        for j in range(r_u[0]):\n            if lab_arr[i,0] == lab_arr_unique[j]:\n                one_hot_enc[i,j] = 1\n    \n    return one_hot_enc\n\n# Function that takes the confusion matrix as input and\n# calculates the overall accuracy, producer's accuracy, user's accuracy,\n# Cohen's kappa coefficient and syandard deviation of \n# Cohen's kappa coefficient\n\ndef accuracies(cm):\n  import numpy as np\n  num_class = np.shape(cm)[0]\n  n = np.sum(cm)\n\n  P = cm/n\n  ovr_acc = np.trace(P)\n\n  p_plus_j = np.sum(P, axis = 0)\n  p_i_plus = np.sum(P, axis = 1)\n\n  usr_acc = np.diagonal(P)/p_i_plus\n  prod_acc = np.diagonal(P)/p_plus_j\n\n  theta1 = np.trace(P)\n  theta2 = np.sum(p_plus_j*p_i_plus)\n  theta3 = np.sum(np.diagonal(P)*(p_plus_j + p_i_plus))\n  theta4 = 0\n  for i in range(num_class):\n    for j in range(num_class):\n      theta4 = theta4+P[i,j]*(p_plus_j[i]+p_i_plus[j])**2\n\n  kappa = (theta1-theta2)/(1-theta2)\n\n  t1 = theta1*(1-theta1)/(1-theta2)**2\n  t2 = 2*(1-theta1)*(2*theta1*theta2-theta3)/(1-theta2)**3\n  t3 = ((1-theta1)**2)*(theta4 - 4*theta2**2)/(1-theta2)**4\n\n  s_sqr = (t1+t2+t3)/n\n\n  return ovr_acc, usr_acc, prod_acc, kappa, s_sqr\n\n# This is the main feature extractor for the hyperpsectral images. \n# The input is a hyperspectral patch. It consists of 6 sets of \n# convolutional, relu and batch normalization operations \n\ndef hs(x):\n    conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name='conv31')(x)\n    conv1 = BatchNormalization()(conv1)\n\n    conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv32')(conv1)\n    conv2 = BatchNormalization()(conv2) \n\n    conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv33')(conv2) \n    conv3 = BatchNormalization()(conv3)\n                           \n    conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv34')(conv3) \n    conv4 = BatchNormalization()(conv4)\n\n    conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv35')(conv4) \n    conv5 = BatchNormalization()(conv5)\n\n    # ASPP module with different dilation rates\n    aspp1 = Conv2D(256, (3, 3), padding='same', dilation_rate=1, activation='relu', name='aspp1')(conv5)\n    aspp2 = Conv2D(256, (3, 3), padding='same', dilation_rate=6, activation='relu', name='aspp2')(conv5)\n    aspp3 = Conv2D(256, (3, 3), padding='same', dilation_rate=12, activation='relu', name='aspp3')(conv5)\n    aspp4 = Conv2D(256, (3, 3), padding='same', dilation_rate=18, activation='relu', name='aspp4')(conv5)\n\n    # Concatenate the ASPP outputs\n    concat = Concatenate()([aspp1, aspp2, aspp3])\n\n    # 1x1 convolution to fuse the features\n    fused = Conv2D(256, (1, 1), padding='same', activation='relu', name='fused')(concat)\n\n    conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv36')(fused) \n\n    conv6 = BatchNormalization()(conv6)\n\n    return conv6\n\n\n# This is the spectral attention mask for hyperspecral images.\n# The input are hyperspectral patches and output is an attention vector \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block and 2D maxpool operation after second and fourth \n# convolution layers. Last convolution layer is followed by a maxpool and \n# Global average pool operation.\n\ndef mask_spec(x):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convc1')(x)\n\n  conv1 = BatchNormalization(name = 'BNc1')(conv1)\n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01),  name = 'convc2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNc2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n  \n  mp1 = MaxPooling2D(pool_size=(2, 2), padding='valid')(res1)\n\n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc3')(mp1) \n\n  conv3 = BatchNormalization(name = 'BNc3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNc4')(conv4)\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n  \n  mp2 = MaxPooling2D(pool_size=(2, 2), padding='valid')(res2)\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc5')(mp2) \n\n  conv5 = BatchNormalization(name = 'BNc5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BNc6')(conv6)\n\n  mp3 = MaxPooling2D(pool_size=(2, 2), padding='valid')(conv6)\n  gap1 = GlobalAveragePooling2D()(mp3)\n\n  return gap1\n\n# This is the spatial attention mask for hyperspecral images.\n# The input are lidar patches and output is an attention tensor \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block after second and fourth \n# convolution layers. \n\ndef mask_spat(x):\n  \n  conv1 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convt1')(x)\n\n  conv1 = BatchNormalization(name = 'BNt1')(conv1)\n\n  conv2 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01),  name = 'convt2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNt2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n\n  conv3 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt3')(res1) \n\n  conv3 = BatchNormalization(name = 'BNt3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNt4')(conv4)\n\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt5')(res2) \n\n  conv5 = BatchNormalization(name = 'BNt5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BNt6')(conv6)\n\n  return conv6\n\n# It is a part of modality attention module.  \n# The input are highlighted spectral and spatial attention features from above modules. \n# It consists of 6 convolutional, relu and batch normalization operations. \n\ndef main2(x):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convm31')(x)\n\n  conv1 = BatchNormalization()(conv1)\n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm32')(conv1)\n\n  conv2 = BatchNormalization()(conv2) \n\n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm33')(conv2) \n\n  conv3 = BatchNormalization()(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm34')(conv3) \n\n  conv4 = BatchNormalization()(conv4)\n  \n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm35')(conv4) \n\n  conv5 = BatchNormalization()(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm36')(conv5) \n\n  conv6 = BatchNormalization()(conv6)\n\n  return conv6\n\n# This is the attention layer for maodality attention module. \n# The input are highlighted spectral and spatial attention features from above modules. \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block after second and fourth \n# convolution layers. \n\ndef att2(x):\n  \n  conv1 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convatt1')(x)\n\n  conv1 = BatchNormalization(name = 'BN2t1')(conv1)\n\n  conv2 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BN2t2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n\n  conv3 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt3')(res1) \n\n  conv3 = BatchNormalization(name = 'BN2t3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BN2t4')(conv4)\n\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt5')(res2) \n\n  conv5 = BatchNormalization(name = 'BN2t5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BN2t6')(conv6)\n\n  return conv6\n\n# This is a classifier function. It is a CNN with 6 layers\n# (convolution + RelU + Batch Normalization). Inputs are \n# Attention assisted enhanced features from modality attention module \n# and number of classes\n\ndef clf(x, num_classes):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convcl1')(x)\n\n  conv1 = BatchNormalization(name = 'BNcl1')(conv1)\n  \n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNcl2')(conv2) \n  \n  \n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl3')(conv2) \n\n  conv3 = BatchNormalization(name = 'BNcl3')(conv3)\n  \n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNcl4')(conv4)\n  \n  conv5 = Conv2D(1024, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl5')(conv4) \n\n  conv5 = BatchNormalization(name = 'BNcl5')(conv5)\n\n  conv6 = Conv2D(num_classes, (1,1), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='softmax', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl6')(conv5) \n  \n\n  return Reshape([num_classes])(conv6)\n\n# reading training and test data\n\ntrain_patches = np.load('/kaggle/working/train_patches.npy')\ntest_patches = np.load('/kaggle/working/test_patches.npy')\n\ntrain_labels = np.load('/kaggle/working/train_labels.npy')\ntest_labels = np.load('/kaggle/working/test_labels.npy')\n\n# Separating HSI and lidar patches from training\n# validation and testing data\n\n#num_hsi_bands = 144\n#num_lidar_bands = 1\n\ntrain_hsi = train_patches[:,:,:,0:144]\ntrain_lidar = np.expand_dims(train_patches[:,:,:,144], axis = 3) # Expanding dimension to preserve shape\n                                                           #since only one band is present\n\ntest_hsi = test_patches[:,:,:,0:144]\ntest_lidar = np.expand_dims(test_patches[:,:,:,144], axis = 3)\n\n## Training module\n\nK.clear_session()\ng = tf.Graph()\n\nk = 0        #k is created to temporarily store the maximum validation accuracy for each epoch\n\nwith g.as_default():\n\n  x1 = Input(shape=(11,11,144), name='inputA')     #num_hsi_bands = 144\n\n  x2 = Input(shape=(11,11,1), name='inputB')      #num_lidar_bands = 1\n\n  feats_new = hs(x1)                              # Main feature extraction\n  print(feats_new)\n\n  # Generating spectral attention mask and spectrally highlighting HSI features\n  spec = Multiply()([feats_new, mask_spec(x1)])   \n  \n  # Generating spatial attention mask  and spatially highlighting HSI features\n  spat = Multiply()([feats_new, mask_spat(x2)]) \n\n  # Concatenationg highlighted features and input features  \n  conc = Concatenate(axis = 3)([x1,x2,spec,spat]) \n\n  feats2 = main2(conc)                            # Modality features extraction\n  mask2 = att2(conc)                              # Modality attention mask\n\n  # Highlighting modality features using modality attention mask\n\n  at_feats = Multiply()([feats2, mask2])  \n\n  clsf = clf(at_feats, 15)                        # Classifier with number of classes = 15\n\n  # Initialising model\n  model_att = Model([x1,x2], clsf, name = 'att_clf')\n\n  # Adam with Nesterov Momentum optimizer\n  optim = keras.optimizers.Nadam(0.00002, beta_1=0.9, beta_2=0.999)\n  \n  # Compiling the model\n  model_att.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n\n  for epoch in range(5):  # Number of epochs = 1000\n    \n    model_att.fit(x = [train_hsi, train_lidar], \n                  y = my_ohc(np.expand_dims(train_labels, axis = 1)),\n                  epochs=1, batch_size = 64, verbose = 1)\n    \n    preds2 = model_att.predict([test_hsi, test_lidar], verbose = 1)\n\n    conf = confusion_matrix(test_labels, np.argmax(preds2,1)) # Test set predictions\n    ovr_acc, _, _, _, _ = accuracies(conf)\n\n    if ovr_acc>=k:\n\n      # Saving model for maximum accuracy     \n      model_att.save('/kaggle/working/Houston/models/model')\n      k = ovr_acc\n      ep = epoch\n    print('acc_max_val = ', np.round(100*k,2), '% at epoch', ep) # Maximum test accuracy\n\n\n# Evaluating the model on test set\n\nK.clear_session()\ng = tf.Graph()\n\nwith g.as_default():\n\n  # Loading saved model\n  model = keras.models.load_model('/kaggle/working/Houston/models/model')\n\n  preds_final = model.predict([test_hsi, test_lidar], verbose = 1)\n  conf_final = confusion_matrix(test_labels, np.argmax(preds_final,1))\n  ovr_acc_final, usr_acc, prod_acc, kappa, s_sqr = accuracies(conf_final)\n\nprint('Test accuracy is ', np.round(100*ovr_acc_final,2), '%') # Final test accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:50:38.509404Z","iopub.execute_input":"2024-04-29T12:50:38.509703Z","iopub.status.idle":"2024-04-29T19:02:16.668345Z","shell.execute_reply.started":"2024-04-29T12:50:38.509676Z","shell.execute_reply":"2024-04-29T19:02:16.667229Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Tensor(\"batch_normalization_5/cond/Identity:0\", shape=(None, 11, 11, 1024), dtype=float32)\nTrain on 11328 samples\n11328/11328 [==============================] - 4014s 354ms/sample - loss: 97.5797 - accuracy: 0.2338\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n  updates=self.state_updates,\n/tmp/ipykernel_34/4078512212.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"acc_max_val =  8.68 % at epoch 0\nTrain on 11328 samples\n11328/11328 [==============================] - 3930s 347ms/sample - loss: 96.1471 - accuracy: 0.5034\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/4078512212.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"acc_max_val =  9.04 % at epoch 1\nTrain on 11328 samples\n11328/11328 [==============================] - 3864s 341ms/sample - loss: 94.8563 - accuracy: 0.7312\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/4078512212.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"acc_max_val =  11.23 % at epoch 2\nTrain on 11328 samples\n11328/11328 [==============================] - 4022s 355ms/sample - loss: 93.8241 - accuracy: 0.8610\nacc_max_val =  11.23 % at epoch 2\nTrain on 11328 samples\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/4078512212.py:47: RuntimeWarning: invalid value encountered in divide\n  usr_acc = np.diagonal(P)/p_i_plus\n/tmp/ipykernel_34/4078512212.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"11328/11328 [==============================] - 3957s 349ms/sample - loss: 92.9057 - accuracy: 0.9245\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/4078512212.py:47: RuntimeWarning: invalid value encountered in divide\n  usr_acc = np.diagonal(P)/p_i_plus\n/tmp/ipykernel_34/4078512212.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"acc_max_val =  11.23 % at epoch 2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n  updates=self.state_updates,\n","output_type":"stream"},{"name":"stdout","text":"Test accuracy is  11.23 %\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/4078512212.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Used two Atrous Spatial Pyramid Pooling (ASPP)layers with dilation rates of 1,6","metadata":{}},{"cell_type":"code","source":"# Import all the necessary libraries and classes\n\nimport numpy as np\nimport tensorflow as tf\nkeras = tf.keras\nfrom keras import backend as K\nfrom keras.layers import Input\nfrom keras.layers import Conv2D, Reshape, BatchNormalization\nfrom keras.layers import Concatenate\nfrom keras.layers import Multiply, GlobalAveragePooling2D, MaxPooling2D\nfrom keras.models import Model\nfrom sklearn.metrics import confusion_matrix\nfrom keras import regularizers\n\n# Function to perform one hot encoding of the class labels \n\ndef my_ohc(lab_arr):\n    lab_arr_unique =  np.unique(lab_arr)\n    r,c = lab_arr.shape\n    r_u  = lab_arr_unique.shape\n    \n    one_hot_enc = np.zeros((r,r_u[0]), dtype = 'float')\n    \n    for i in range(r):\n        for j in range(r_u[0]):\n            if lab_arr[i,0] == lab_arr_unique[j]:\n                one_hot_enc[i,j] = 1\n    \n    return one_hot_enc\n\n# Function that takes the confusion matrix as input and\n# calculates the overall accuracy, producer's accuracy, user's accuracy,\n# Cohen's kappa coefficient and syandard deviation of \n# Cohen's kappa coefficient\n\ndef accuracies(cm):\n  import numpy as np\n  num_class = np.shape(cm)[0]\n  n = np.sum(cm)\n\n  P = cm/n\n  ovr_acc = np.trace(P)\n\n  p_plus_j = np.sum(P, axis = 0)\n  p_i_plus = np.sum(P, axis = 1)\n\n  usr_acc = np.diagonal(P)/p_i_plus\n  prod_acc = np.diagonal(P)/p_plus_j\n\n  theta1 = np.trace(P)\n  theta2 = np.sum(p_plus_j*p_i_plus)\n  theta3 = np.sum(np.diagonal(P)*(p_plus_j + p_i_plus))\n  theta4 = 0\n  for i in range(num_class):\n    for j in range(num_class):\n      theta4 = theta4+P[i,j]*(p_plus_j[i]+p_i_plus[j])**2\n\n  kappa = (theta1-theta2)/(1-theta2)\n\n  t1 = theta1*(1-theta1)/(1-theta2)**2\n  t2 = 2*(1-theta1)*(2*theta1*theta2-theta3)/(1-theta2)**3\n  t3 = ((1-theta1)**2)*(theta4 - 4*theta2**2)/(1-theta2)**4\n\n  s_sqr = (t1+t2+t3)/n\n\n  return ovr_acc, usr_acc, prod_acc, kappa, s_sqr\n\n# This is the main feature extractor for the hyperpsectral images. \n# The input is a hyperspectral patch. It consists of 6 sets of \n# convolutional, relu and batch normalization operations \n\ndef hs(x):\n    conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name='conv31')(x)\n    conv1 = BatchNormalization()(conv1)\n\n    conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(2, 2), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv32')(conv1)\n    conv2 = BatchNormalization()(conv2) \n\n    conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(4, 4), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv33')(conv2) \n    conv3 = BatchNormalization()(conv3)\n                           \n    conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(6, 6), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv34')(conv3) \n    conv4 = BatchNormalization()(conv4)\n\n    conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(8, 8), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv35')(conv4) \n    conv5 = BatchNormalization()(conv5)\n\n    # ASPP module with different dilation rates\n    aspp1 = Conv2D(256, (1, 1), padding='same', dilation_rate=1, activation='relu', name='aspp1')(conv5)\n    aspp2 = Conv2D(256, (3, 3), padding='same', dilation_rate=6, activation='relu', name='aspp2')(conv5)\n\n    # Concatenate the ASPP outputs\n    concat = Concatenate()([aspp1, aspp2])\n\n    # 1x1 convolution to fuse the features\n    fused = Conv2D(256, (1, 1), padding='same', activation='relu', name='fused')(concat)\n\n    conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv36')(fused) \n\n    conv6 = BatchNormalization()(conv6)\n\n    return conv6\n\n\n\n# This is the spectral attention mask for hyperspecral images.\n# The input are hyperspectral patches and output is an attention vector \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block and 2D maxpool operation after second and fourth \n# convolution layers. Last convolution layer is followed by a maxpool and \n# Global average pool operation.\n\ndef mask_spec(x):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convc1')(x)\n\n  conv1 = BatchNormalization(name = 'BNc1')(conv1)\n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01),  name = 'convc2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNc2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n  \n  mp1 = MaxPooling2D(pool_size=(2, 2), padding='valid')(res1)\n\n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc3')(mp1) \n\n  conv3 = BatchNormalization(name = 'BNc3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNc4')(conv4)\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n  \n  mp2 = MaxPooling2D(pool_size=(2, 2), padding='valid')(res2)\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc5')(mp2) \n\n  conv5 = BatchNormalization(name = 'BNc5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BNc6')(conv6)\n\n  mp3 = MaxPooling2D(pool_size=(2, 2), padding='valid')(conv6)\n  gap1 = GlobalAveragePooling2D()(mp3)\n\n  return gap1\n\n# This is the spatial attention mask for hyperspecral images.\n# The input are lidar patches and output is an attention tensor \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block after second and fourth \n# convolution layers. \n\ndef mask_spat(x):\n  \n  conv1 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convt1')(x)\n\n  conv1 = BatchNormalization(name = 'BNt1')(conv1)\n\n  conv2 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01),  name = 'convt2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNt2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n\n  conv3 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt3')(res1) \n\n  conv3 = BatchNormalization(name = 'BNt3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNt4')(conv4)\n\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt5')(res2) \n\n  conv5 = BatchNormalization(name = 'BNt5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BNt6')(conv6)\n\n  return conv6\n\n# It is a part of modality attention module.  \n# The input are highlighted spectral and spatial attention features from above modules. \n# It consists of 6 convolutional, relu and batch normalization operations. \n\ndef main2(x):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convm31')(x)\n\n  conv1 = BatchNormalization()(conv1)\n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm32')(conv1)\n\n  conv2 = BatchNormalization()(conv2) \n\n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm33')(conv2) \n\n  conv3 = BatchNormalization()(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm34')(conv3) \n\n  conv4 = BatchNormalization()(conv4)\n  \n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm35')(conv4) \n\n  conv5 = BatchNormalization()(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm36')(conv5) \n\n  conv6 = BatchNormalization()(conv6)\n\n  return conv6\n\n# This is the attention layer for maodality attention module. \n# The input are highlighted spectral and spatial attention features from above modules. \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block after second and fourth \n# convolution layers. \n\ndef att2(x):\n  \n  conv1 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convatt1')(x)\n\n  conv1 = BatchNormalization(name = 'BN2t1')(conv1)\n\n  conv2 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BN2t2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n\n  conv3 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt3')(res1) \n\n  conv3 = BatchNormalization(name = 'BN2t3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BN2t4')(conv4)\n\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt5')(res2) \n\n  conv5 = BatchNormalization(name = 'BN2t5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BN2t6')(conv6)\n\n  return conv6\n\n# This is a classifier function. It is a CNN with 6 layers\n# (convolution + RelU + Batch Normalization). Inputs are \n# Attention assisted enhanced features from modality attention module \n# and number of classes\n\ndef clf(x, num_classes):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convcl1')(x)\n\n  conv1 = BatchNormalization(name = 'BNcl1')(conv1)\n  \n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNcl2')(conv2) \n  \n  \n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl3')(conv2) \n\n  conv3 = BatchNormalization(name = 'BNcl3')(conv3)\n  \n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNcl4')(conv4)\n  \n  conv5 = Conv2D(1024, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl5')(conv4) \n\n  conv5 = BatchNormalization(name = 'BNcl5')(conv5)\n\n  conv6 = Conv2D(num_classes, (1,1), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='softmax', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl6')(conv5) \n  \n\n  return Reshape([num_classes])(conv6)\n\n# reading training and test data\n\ntrain_patches = np.load('/kaggle/working/train_patches.npy')\ntest_patches = np.load('/kaggle/working/test_patches.npy')\n\ntrain_labels = np.load('/kaggle/working/train_labels.npy')\ntest_labels = np.load('/kaggle/working/test_labels.npy')\n\n# Separating HSI and lidar patches from training\n# validation and testing data\n\n#num_hsi_bands = 144\n#num_lidar_bands = 1\n\ntrain_hsi = train_patches[:,:,:,0:144]\ntrain_lidar = np.expand_dims(train_patches[:,:,:,144], axis = 3) # Expanding dimension to preserve shape\n                                                           #since only one band is present\n\ntest_hsi = test_patches[:,:,:,0:144]\ntest_lidar = np.expand_dims(test_patches[:,:,:,144], axis = 3)\n\n## Training module\n\nK.clear_session()\ng = tf.Graph()\n\nk = 0        #k is created to temporarily store the maximum validation accuracy for each epoch\n\nwith g.as_default():\n\n  x1 = Input(shape=(11,11,144), name='inputA')     #num_hsi_bands = 144\n\n  x2 = Input(shape=(11,11,1), name='inputB')      #num_lidar_bands = 1\n\n  feats_new = hs(x1)                              # Main feature extraction\n  print(feats_new)\n\n  # Generating spectral attention mask and spectrally highlighting HSI features\n  spec = Multiply()([feats_new, mask_spec(x1)])   \n  \n  # Generating spatial attention mask  and spatially highlighting HSI features\n  spat = Multiply()([feats_new, mask_spat(x2)]) \n\n  # Concatenationg highlighted features and input features  \n  conc = Concatenate(axis = 3)([x1,x2,spec,spat]) \n\n  feats2 = main2(conc)                            # Modality features extraction\n  mask2 = att2(conc)                              # Modality attention mask\n\n  # Highlighting modality features using modality attention mask\n\n  at_feats = Multiply()([feats2, mask2])  \n\n  clsf = clf(at_feats, 15)                        # Classifier with number of classes = 15\n\n  # Initialising model\n  model_att = Model([x1,x2], clsf, name = 'att_clf')\n\n  # Adam with Nesterov Momentum optimizer\n  optim = keras.optimizers.Nadam(0.00002, beta_1=0.9, beta_2=0.999)\n  \n  # Compiling the model\n  model_att.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n\n  for epoch in range(5):  # Number of epochs = 1000\n    \n    model_att.fit(x = [train_hsi, train_lidar], \n                  y = my_ohc(np.expand_dims(train_labels, axis = 1)),\n                  epochs=1, batch_size = 64, verbose = 1)\n    \n    preds2 = model_att.predict([test_hsi, test_lidar], verbose = 1)\n\n    conf = confusion_matrix(test_labels, np.argmax(preds2,1)) # Test set predictions\n    ovr_acc, _, _, _, _ = accuracies(conf)\n\n    if ovr_acc>=k:\n\n      # Saving model for maximum accuracy     \n      model_att.save('/kaggle/working/Houston/models/model')\n      k = ovr_acc\n      ep = epoch\n    print('acc_max_val = ', np.round(100*k,2), '% at epoch', ep) # Maximum test accuracy\n\n\n# Evaluating the model on test set\n\nK.clear_session()\ng = tf.Graph()\n\nwith g.as_default():\n\n  # Loading saved model\n  model = keras.models.load_model('/kaggle/working/Houston/models/model')\n\n  preds_final = model.predict([test_hsi, test_lidar], verbose = 1)\n  conf_final = confusion_matrix(test_labels, np.argmax(preds_final,1))\n  ovr_acc_final, usr_acc, prod_acc, kappa, s_sqr = accuracies(conf_final)\n\nprint('Test accuracy is ', np.round(100*ovr_acc_final,2), '%') # Final test accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-28T02:51:22.154116Z","iopub.execute_input":"2024-04-28T02:51:22.154483Z","iopub.status.idle":"2024-04-28T08:34:19.246353Z","shell.execute_reply.started":"2024-04-28T02:51:22.154442Z","shell.execute_reply":"2024-04-28T08:34:19.245454Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Tensor(\"batch_normalization_5/cond/Identity:0\", shape=(None, 11, 11, 1024), dtype=float32)\nTrain on 11328 samples\n11328/11328 [==============================] - 3599s 318ms/sample - loss: 97.4892 - accuracy: 0.2609\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n  updates=self.state_updates,\n/tmp/ipykernel_34/308705013.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"acc_max_val =  8.49 % at epoch 0\nTrain on 11328 samples\n11328/11328 [==============================] - 3628s 320ms/sample - loss: 96.1527 - accuracy: 0.5049\nacc_max_val =  8.49 % at epoch 0\nTrain on 11328 samples\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/308705013.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"11328/11328 [==============================] - 3585s 316ms/sample - loss: 94.9952 - accuracy: 0.6730\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/308705013.py:47: RuntimeWarning: invalid value encountered in divide\n  usr_acc = np.diagonal(P)/p_i_plus\n/tmp/ipykernel_34/308705013.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"acc_max_val =  12.58 % at epoch 2\nTrain on 11328 samples\n11328/11328 [==============================] - 3717s 328ms/sample - loss: 93.9661 - accuracy: 0.8154\nacc_max_val =  12.58 % at epoch 2\nTrain on 11328 samples\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/308705013.py:47: RuntimeWarning: invalid value encountered in divide\n  usr_acc = np.diagonal(P)/p_i_plus\n/tmp/ipykernel_34/308705013.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"11328/11328 [==============================] - 3648s 322ms/sample - loss: 93.0523 - accuracy: 0.8909\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/308705013.py:47: RuntimeWarning: invalid value encountered in divide\n  usr_acc = np.diagonal(P)/p_i_plus\n/tmp/ipykernel_34/308705013.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"acc_max_val =  12.58 % at epoch 2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n  updates=self.state_updates,\n","output_type":"stream"},{"name":"stdout","text":"Test accuracy is  12.58 %\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/308705013.py:47: RuntimeWarning: invalid value encountered in divide\n  usr_acc = np.diagonal(P)/p_i_plus\n/tmp/ipykernel_34/308705013.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Used two Atrous Spatial Pyramid Pooling (ASPP)layers with dilation rates of 6 and 12","metadata":{}},{"cell_type":"code","source":"# Import all the necessary libraries and classes\n\nimport numpy as np\nimport tensorflow as tf\nkeras = tf.keras\nfrom keras import backend as K\nfrom keras.layers import Input\nfrom keras.layers import Conv2D, Reshape, BatchNormalization\nfrom keras.layers import Concatenate\nfrom keras.layers import Multiply, GlobalAveragePooling2D, MaxPooling2D\nfrom keras.models import Model\nfrom sklearn.metrics import confusion_matrix\nfrom keras import regularizers\n\n# Function to perform one hot encoding of the class labels \n\ndef my_ohc(lab_arr):\n    lab_arr_unique =  np.unique(lab_arr)\n    r,c = lab_arr.shape\n    r_u  = lab_arr_unique.shape\n    \n    one_hot_enc = np.zeros((r,r_u[0]), dtype = 'float')\n    \n    for i in range(r):\n        for j in range(r_u[0]):\n            if lab_arr[i,0] == lab_arr_unique[j]:\n                one_hot_enc[i,j] = 1\n    \n    return one_hot_enc\n\n# Function that takes the confusion matrix as input and\n# calculates the overall accuracy, producer's accuracy, user's accuracy,\n# Cohen's kappa coefficient and syandard deviation of \n# Cohen's kappa coefficient\n\ndef accuracies(cm):\n  import numpy as np\n  num_class = np.shape(cm)[0]\n  n = np.sum(cm)\n\n  P = cm/n\n  ovr_acc = np.trace(P)\n\n  p_plus_j = np.sum(P, axis = 0)\n  p_i_plus = np.sum(P, axis = 1)\n\n  usr_acc = np.diagonal(P)/p_i_plus\n  prod_acc = np.diagonal(P)/p_plus_j\n\n  theta1 = np.trace(P)\n  theta2 = np.sum(p_plus_j*p_i_plus)\n  theta3 = np.sum(np.diagonal(P)*(p_plus_j + p_i_plus))\n  theta4 = 0\n  for i in range(num_class):\n    for j in range(num_class):\n      theta4 = theta4+P[i,j]*(p_plus_j[i]+p_i_plus[j])**2\n\n  kappa = (theta1-theta2)/(1-theta2)\n\n  t1 = theta1*(1-theta1)/(1-theta2)**2\n  t2 = 2*(1-theta1)*(2*theta1*theta2-theta3)/(1-theta2)**3\n  t3 = ((1-theta1)**2)*(theta4 - 4*theta2**2)/(1-theta2)**4\n\n  s_sqr = (t1+t2+t3)/n\n\n  return ovr_acc, usr_acc, prod_acc, kappa, s_sqr\n\n# This is the main feature extractor for the hyperpsectral images. \n# The input is a hyperspectral patch. It consists of 6 sets of \n# convolutional, relu and batch normalization operations \n\n\ndef hs(x):\n    conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name='conv31')(x)\n    conv1 = BatchNormalization()(conv1)\n\n    conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(2, 2), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv32')(conv1)\n    conv2 = BatchNormalization()(conv2) \n\n    conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(4, 4), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv33')(conv2) \n    conv3 = BatchNormalization()(conv3)\n                           \n    conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(6, 6), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv34')(conv3) \n    conv4 = BatchNormalization()(conv4)\n\n    conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(8, 8), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv35')(conv4) \n    conv5 = BatchNormalization()(conv5)\n\n    # ASPP module with different dilation rates\n    aspp1 = Conv2D(256, (3, 3), padding='same', dilation_rate=6, activation='relu', name='aspp1')(conv5)\n    aspp2 = Conv2D(256, (3, 3), padding='same', dilation_rate=12, activation='relu', name='aspp2')(conv5)\n\n    # Concatenate the ASPP outputs\n    concat = Concatenate()([aspp1, aspp2])\n\n    # 1x1 convolution to fuse the features\n    fused = Conv2D(256, (1, 1), padding='same', activation='relu', name='fused')(concat)\n\n    conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv36')(fused) \n\n    conv6 = BatchNormalization()(conv6)\n\n    return conv6\n\n# This is the spectral attention mask for hyperspecral images.\n# The input are hyperspectral patches and output is an attention vector \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block and 2D maxpool operation after second and fourth \n# convolution layers. Last convolution layer is followed by a maxpool and \n# Global average pool operation.\n\ndef mask_spec(x):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convc1')(x)\n\n  conv1 = BatchNormalization(name = 'BNc1')(conv1)\n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01),  name = 'convc2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNc2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n  \n  mp1 = MaxPooling2D(pool_size=(2, 2), padding='valid')(res1)\n\n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc3')(mp1) \n\n  conv3 = BatchNormalization(name = 'BNc3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNc4')(conv4)\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n  \n  mp2 = MaxPooling2D(pool_size=(2, 2), padding='valid')(res2)\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc5')(mp2) \n\n  conv5 = BatchNormalization(name = 'BNc5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BNc6')(conv6)\n\n  mp3 = MaxPooling2D(pool_size=(2, 2), padding='valid')(conv6)\n  gap1 = GlobalAveragePooling2D()(mp3)\n\n  return gap1\n\n# This is the spatial attention mask for hyperspecral images.\n# The input are lidar patches and output is an attention tensor \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block after second and fourth \n# convolution layers. \n\ndef mask_spat(x):\n  \n  conv1 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convt1')(x)\n\n  conv1 = BatchNormalization(name = 'BNt1')(conv1)\n\n  conv2 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01),  name = 'convt2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNt2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n\n  conv3 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt3')(res1) \n\n  conv3 = BatchNormalization(name = 'BNt3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNt4')(conv4)\n\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt5')(res2) \n\n  conv5 = BatchNormalization(name = 'BNt5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BNt6')(conv6)\n\n  return conv6\n\n# It is a part of modality attention module.  \n# The input are highlighted spectral and spatial attention features from above modules. \n# It consists of 6 convolutional, relu and batch normalization operations. \n\ndef main2(x):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convm31')(x)\n\n  conv1 = BatchNormalization()(conv1)\n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm32')(conv1)\n\n  conv2 = BatchNormalization()(conv2) \n\n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm33')(conv2) \n\n  conv3 = BatchNormalization()(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm34')(conv3) \n\n  conv4 = BatchNormalization()(conv4)\n  \n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm35')(conv4) \n\n  conv5 = BatchNormalization()(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm36')(conv5) \n\n  conv6 = BatchNormalization()(conv6)\n\n  return conv6\n\n# This is the attention layer for maodality attention module. \n# The input are highlighted spectral and spatial attention features from above modules. \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block after second and fourth \n# convolution layers. \n\ndef att2(x):\n  \n  conv1 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convatt1')(x)\n\n  conv1 = BatchNormalization(name = 'BN2t1')(conv1)\n\n  conv2 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BN2t2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n\n  conv3 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt3')(res1) \n\n  conv3 = BatchNormalization(name = 'BN2t3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BN2t4')(conv4)\n\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt5')(res2) \n\n  conv5 = BatchNormalization(name = 'BN2t5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BN2t6')(conv6)\n\n  return conv6\n\n# This is a classifier function. It is a CNN with 6 layers\n# (convolution + RelU + Batch Normalization). Inputs are \n# Attention assisted enhanced features from modality attention module \n# and number of classes\n\ndef clf(x, num_classes):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convcl1')(x)\n\n  conv1 = BatchNormalization(name = 'BNcl1')(conv1)\n  \n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNcl2')(conv2) \n  \n  \n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl3')(conv2) \n\n  conv3 = BatchNormalization(name = 'BNcl3')(conv3)\n  \n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNcl4')(conv4)\n  \n  conv5 = Conv2D(1024, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl5')(conv4) \n\n  conv5 = BatchNormalization(name = 'BNcl5')(conv5)\n\n  conv6 = Conv2D(num_classes, (1,1), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='softmax', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl6')(conv5) \n  \n\n  return Reshape([num_classes])(conv6)\n\n# reading training and test data\n\ntrain_patches = np.load('/kaggle/working/train_patches.npy')\ntest_patches = np.load('/kaggle/working/test_patches.npy')\n\ntrain_labels = np.load('/kaggle/working/train_labels.npy')\ntest_labels = np.load('/kaggle/working/test_labels.npy')\n\n# Separating HSI and lidar patches from training\n# validation and testing data\n\n#num_hsi_bands = 144\n#num_lidar_bands = 1\n\ntrain_hsi = train_patches[:,:,:,0:144]\ntrain_lidar = np.expand_dims(train_patches[:,:,:,144], axis = 3) # Expanding dimension to preserve shape\n                                                           #since only one band is present\n\ntest_hsi = test_patches[:,:,:,0:144]\ntest_lidar = np.expand_dims(test_patches[:,:,:,144], axis = 3)\n\n## Training module\n\nK.clear_session()\ng = tf.Graph()\n\nk = 0        #k is created to temporarily store the maximum validation accuracy for each epoch\n\nwith g.as_default():\n\n  x1 = Input(shape=(11,11,144), name='inputA')     #num_hsi_bands = 144\n\n  x2 = Input(shape=(11,11,1), name='inputB')      #num_lidar_bands = 1\n\n  feats_new = hs(x1)                              # Main feature extraction\n  print(feats_new)\n\n  # Generating spectral attention mask and spectrally highlighting HSI features\n  spec = Multiply()([feats_new, mask_spec(x1)])   \n  \n  # Generating spatial attention mask  and spatially highlighting HSI features\n  spat = Multiply()([feats_new, mask_spat(x2)]) \n\n  # Concatenationg highlighted features and input features  \n  conc = Concatenate(axis = 3)([x1,x2,spec,spat]) \n\n  feats2 = main2(conc)                            # Modality features extraction\n  mask2 = att2(conc)                              # Modality attention mask\n\n  # Highlighting modality features using modality attention mask\n\n  at_feats = Multiply()([feats2, mask2])  \n\n  clsf = clf(at_feats, 15)                        # Classifier with number of classes = 15\n\n  # Initialising model\n  model_att = Model([x1,x2], clsf, name = 'att_clf')\n\n  # Adam with Nesterov Momentum optimizer\n  optim = keras.optimizers.Nadam(0.00002, beta_1=0.9, beta_2=0.999)\n  \n  # Compiling the model\n  model_att.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n\n  for epoch in range(20):  # Number of epochs = 1000\n    \n    model_att.fit(x = [train_hsi, train_lidar], \n                  y = my_ohc(np.expand_dims(train_labels, axis = 1)),\n                  epochs=1, batch_size = 64, verbose = 1)\n    \n    preds2 = model_att.predict([test_hsi, test_lidar], verbose = 1)\n\n    conf = confusion_matrix(test_labels, np.argmax(preds2,1)) # Test set predictions\n    ovr_acc, _, _, _, _ = accuracies(conf)\n    print(\"epoch\",epoch, \"ovr_acc\",ovr_acc)\n\n    if ovr_acc>=k:\n\n      # Saving model for maximum accuracy     \n      model_att.save('/kaggle/working/Houston/models/model')\n      k = ovr_acc\n      ep = epoch\n    print('acc_max_val = ', np.round(100*k,2), '% at epoch', ep) # Maximum test accuracy\n\n\n# Evaluating the model on test set\nprint(\"testing starts\",\"k\",k,\"ovr_acc\",ovr_acc)\n\nK.clear_session()\ng = tf.Graph()\n\nwith g.as_default():\n\n  # Loading saved model\n  model = keras.models.load_model('/kaggle/working/Houston/models/model')\n\n  preds_final = model.predict([test_hsi, test_lidar], verbose = 1)\n  conf_final = confusion_matrix(test_labels, np.argmax(preds_final,1))\n  ovr_acc_final, usr_acc, prod_acc, kappa, s_sqr = accuracies(conf_final)\n\nprint('Test accuracy is ', np.round(100*ovr_acc_final,2), '%') # Final test accuracy","metadata":{"execution":{"iopub.status.busy":"2024-04-29T20:34:24.800738Z","iopub.execute_input":"2024-04-29T20:34:24.801176Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Tensor(\"batch_normalization_5/cond/Identity:0\", shape=(None, 11, 11, 1024), dtype=float32)\nTrain on 11328 samples\n11328/11328 [==============================] - 6443s 569ms/sample - loss: 97.5327 - accuracy: 0.2542\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n  updates=self.state_updates,\n/tmp/ipykernel_33/1916549740.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"epoch 0 ovr_acc 0.02336640157415758\nacc_max_val =  2.34 % at epoch 0\nTrain on 11328 samples\n11328/11328 [==============================] - 6389s 564ms/sample - loss: 96.2144 - accuracy: 0.4733\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1916549740.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"epoch 1 ovr_acc 0.025416085922767895\nacc_max_val =  2.54 % at epoch 1\nTrain on 11328 samples\n11328/11328 [==============================] - 6371s 562ms/sample - loss: 95.0648 - accuracy: 0.6532\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1916549740.py:47: RuntimeWarning: invalid value encountered in divide\n  usr_acc = np.diagonal(P)/p_i_plus\n/tmp/ipykernel_33/1916549740.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"epoch 2 ovr_acc 0.12093137656800852\nacc_max_val =  12.09 % at epoch 2\nTrain on 11328 samples\n11328/11328 [==============================] - 6355s 561ms/sample - loss: 94.0488 - accuracy: 0.7843\nepoch 3 ovr_acc 0.08772649012052144\nacc_max_val =  12.09 % at epoch 2\nTrain on 11328 samples\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1916549740.py:47: RuntimeWarning: invalid value encountered in divide\n  usr_acc = np.diagonal(P)/p_i_plus\n/tmp/ipykernel_33/1916549740.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"11328/11328 [==============================] - 6357s 561ms/sample - loss: 93.1124 - accuracy: 0.8700\nepoch 4 ovr_acc 0.022382553086824627\nacc_max_val =  12.09 % at epoch 2\nTrain on 11328 samples\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1916549740.py:47: RuntimeWarning: invalid value encountered in divide\n  usr_acc = np.diagonal(P)/p_i_plus\n/tmp/ipykernel_33/1916549740.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"11328/11328 [==============================] - 6345s 560ms/sample - loss: 92.2162 - accuracy: 0.9299\nepoch 5 ovr_acc 0.020824792981880794\nacc_max_val =  12.09 % at epoch 2\nTrain on 11328 samples\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1916549740.py:47: RuntimeWarning: invalid value encountered in divide\n  usr_acc = np.diagonal(P)/p_i_plus\n/tmp/ipykernel_33/1916549740.py:48: RuntimeWarning: invalid value encountered in divide\n  prod_acc = np.diagonal(P)/p_plus_j\n","output_type":"stream"},{"name":"stdout","text":"  768/11328 [=>............................] - ETA: 1:39:27 - loss: 91.7251 - accuracy: 0.9544","output_type":"stream"}]},{"cell_type":"markdown","source":"# Used five Atrous Spatial Pyramid Pooling (ASPP)layers with dilation rates of 1,6,12,18 and 24","metadata":{}},{"cell_type":"code","source":"# Import all the necessary libraries and classes\n\nimport numpy as np\nimport tensorflow as tf\nkeras = tf.keras\nfrom keras import backend as K\nfrom keras.layers import Input\nfrom keras.layers import Conv2D, Reshape, BatchNormalization\nfrom keras.layers import Concatenate\nfrom keras.layers import Multiply, GlobalAveragePooling2D, MaxPooling2D\nfrom keras.models import Model\nfrom sklearn.metrics import confusion_matrix\nfrom keras import regularizers\n\n# Function to perform one hot encoding of the class labels \n\ndef my_ohc(lab_arr):\n    lab_arr_unique =  np.unique(lab_arr)\n    r,c = lab_arr.shape\n    r_u  = lab_arr_unique.shape\n    \n    one_hot_enc = np.zeros((r,r_u[0]), dtype = 'float')\n    \n    for i in range(r):\n        for j in range(r_u[0]):\n            if lab_arr[i,0] == lab_arr_unique[j]:\n                one_hot_enc[i,j] = 1\n    \n    return one_hot_enc\n\n# Function that takes the confusion matrix as input and\n# calculates the overall accuracy, producer's accuracy, user's accuracy,\n# Cohen's kappa coefficient and syandard deviation of \n# Cohen's kappa coefficient\n\ndef accuracies(cm):\n  import numpy as np\n  num_class = np.shape(cm)[0]\n  n = np.sum(cm)\n\n  P = cm/n\n  ovr_acc = np.trace(P)\n\n  p_plus_j = np.sum(P, axis = 0)\n  p_i_plus = np.sum(P, axis = 1)\n\n  usr_acc = np.diagonal(P)/p_i_plus\n  prod_acc = np.diagonal(P)/p_plus_j\n\n  theta1 = np.trace(P)\n  theta2 = np.sum(p_plus_j*p_i_plus)\n  theta3 = np.sum(np.diagonal(P)*(p_plus_j + p_i_plus))\n  theta4 = 0\n  for i in range(num_class):\n    for j in range(num_class):\n      theta4 = theta4+P[i,j]*(p_plus_j[i]+p_i_plus[j])**2\n\n  kappa = (theta1-theta2)/(1-theta2)\n\n  t1 = theta1*(1-theta1)/(1-theta2)**2\n  t2 = 2*(1-theta1)*(2*theta1*theta2-theta3)/(1-theta2)**3\n  t3 = ((1-theta1)**2)*(theta4 - 4*theta2**2)/(1-theta2)**4\n\n  s_sqr = (t1+t2+t3)/n\n\n  return ovr_acc, usr_acc, prod_acc, kappa, s_sqr\n\n# This is the main feature extractor for the hyperpsectral images. \n# The input is a hyperspectral patch. It consists of 6 sets of \n# convolutional, relu and batch normalization operations \n\ndef hs(x):\n    conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name='conv31')(x)\n    conv1 = BatchNormalization()(conv1)\n\n    conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(2, 2), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv32')(conv1)\n    conv2 = BatchNormalization()(conv2) \n\n    conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(4, 4), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv33')(conv2) \n    conv3 = BatchNormalization()(conv3)\n                           \n    conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(6, 6), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv34')(conv3) \n    conv4 = BatchNormalization()(conv4)\n\n    conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(8, 8), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv35')(conv4) \n    conv5 = BatchNormalization()(conv5)\n\n    # ASPP module with different dilation rates\n    aspp1 = Conv2D(256, (1, 1), padding='same', dilation_rate=1, activation='relu', name='aspp1')(conv5)\n    aspp2 = Conv2D(256, (3, 3), padding='same', dilation_rate=6, activation='relu', name='aspp2')(conv5)\n    aspp3 = Conv2D(256, (3, 3), padding='same', dilation_rate=12, activation='relu', name='aspp3')(conv5)\n    aspp4 = Conv2D(256, (3, 3), padding='same', dilation_rate=18, activation='relu', name='aspp4')(conv5)\n    aspp5 = Conv2D(256, (3, 3), padding='same', dilation_rate=24, activation='relu', name='aspp5')(conv5)\n\n    # Concatenate the ASPP outputs\n    concat = Concatenate()([aspp1, aspp2, aspp3, aspp4,aspp5 ])\n\n    # 1x1 convolution to fuse the features\n    fused = Conv2D(256, (1, 1), padding='same', activation='relu', name='fused')(concat)\n\n    conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv36')(fused) \n\n    conv6 = BatchNormalization()(conv6)\n\n    return conv6\n\n# This is the spectral attention mask for hyperspecral images.\n# The input are hyperspectral patches and output is an attention vector \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block and 2D maxpool operation after second and fourth \n# convolution layers. Last convolution layer is followed by a maxpool and \n# Global average pool operation.\n\ndef mask_spec(x):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convc1')(x)\n\n  conv1 = BatchNormalization(name = 'BNc1')(conv1)\n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01),  name = 'convc2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNc2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n  \n  mp1 = MaxPooling2D(pool_size=(2, 2), padding='valid')(res1)\n\n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc3')(mp1) \n\n  conv3 = BatchNormalization(name = 'BNc3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNc4')(conv4)\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n  \n  mp2 = MaxPooling2D(pool_size=(2, 2), padding='valid')(res2)\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc5')(mp2) \n\n  conv5 = BatchNormalization(name = 'BNc5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BNc6')(conv6)\n\n  mp3 = MaxPooling2D(pool_size=(2, 2), padding='valid')(conv6)\n  gap1 = GlobalAveragePooling2D()(mp3)\n\n  return gap1\n\n# This is the spatial attention mask for hyperspecral images.\n# The input are lidar patches and output is an attention tensor \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block after second and fourth \n# convolution layers. \n\ndef mask_spat(x):\n  \n  conv1 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convt1')(x)\n\n  conv1 = BatchNormalization(name = 'BNt1')(conv1)\n\n  conv2 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01),  name = 'convt2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNt2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n\n  conv3 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt3')(res1) \n\n  conv3 = BatchNormalization(name = 'BNt3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNt4')(conv4)\n\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt5')(res2) \n\n  conv5 = BatchNormalization(name = 'BNt5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BNt6')(conv6)\n\n  return conv6\n\n# It is a part of modality attention module.  \n# The input are highlighted spectral and spatial attention features from above modules. \n# It consists of 6 convolutional, relu and batch normalization operations. \n\ndef main2(x):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convm31')(x)\n\n  conv1 = BatchNormalization()(conv1)\n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm32')(conv1)\n\n  conv2 = BatchNormalization()(conv2) \n\n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm33')(conv2) \n\n  conv3 = BatchNormalization()(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm34')(conv3) \n\n  conv4 = BatchNormalization()(conv4)\n  \n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm35')(conv4) \n\n  conv5 = BatchNormalization()(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm36')(conv5) \n\n  conv6 = BatchNormalization()(conv6)\n\n  return conv6\n\n# This is the attention layer for maodality attention module. \n# The input are highlighted spectral and spatial attention features from above modules. \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block after second and fourth \n# convolution layers. \n\ndef att2(x):\n  \n  conv1 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convatt1')(x)\n\n  conv1 = BatchNormalization(name = 'BN2t1')(conv1)\n\n  conv2 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BN2t2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n\n  conv3 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt3')(res1) \n\n  conv3 = BatchNormalization(name = 'BN2t3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BN2t4')(conv4)\n\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt5')(res2) \n\n  conv5 = BatchNormalization(name = 'BN2t5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BN2t6')(conv6)\n\n  return conv6\n\n# This is a classifier function. It is a CNN with 6 layers\n# (convolution + RelU + Batch Normalization). Inputs are \n# Attention assisted enhanced features from modality attention module \n# and number of classes\n\ndef clf(x, num_classes):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convcl1')(x)\n\n  conv1 = BatchNormalization(name = 'BNcl1')(conv1)\n  \n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNcl2')(conv2) \n  \n  \n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl3')(conv2) \n\n  conv3 = BatchNormalization(name = 'BNcl3')(conv3)\n  \n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNcl4')(conv4)\n  \n  conv5 = Conv2D(1024, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl5')(conv4) \n\n  conv5 = BatchNormalization(name = 'BNcl5')(conv5)\n\n  conv6 = Conv2D(num_classes, (1,1), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='softmax', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl6')(conv5) \n  \n\n  return Reshape([num_classes])(conv6)\n\n# reading training and test data\n\ntrain_patches = np.load('/kaggle/working/train_patches.npy')\ntest_patches = np.load('/kaggle/working/test_patches.npy')\n\ntrain_labels = np.load('/kaggle/working/train_labels.npy')\ntest_labels = np.load('/kaggle/working/test_labels.npy')\n\n# Separating HSI and lidar patches from training\n# validation and testing data\n\n#num_hsi_bands = 144\n#num_lidar_bands = 1\n\ntrain_hsi = train_patches[:,:,:,0:144]\ntrain_lidar = np.expand_dims(train_patches[:,:,:,144], axis = 3) # Expanding dimension to preserve shape\n                                                           #since only one band is present\n\ntest_hsi = test_patches[:,:,:,0:144]\ntest_lidar = np.expand_dims(test_patches[:,:,:,144], axis = 3)\n\n## Training module\n\nK.clear_session()\ng = tf.Graph()\n\nk = 0        #k is created to temporarily store the maximum validation accuracy for each epoch\n\nwith g.as_default():\n\n  x1 = Input(shape=(11,11,144), name='inputA')     #num_hsi_bands = 144\n\n  x2 = Input(shape=(11,11,1), name='inputB')      #num_lidar_bands = 1\n\n  feats_new = hs(x1)                              # Main feature extraction\n  print(feats_new)\n\n  # Generating spectral attention mask and spectrally highlighting HSI features\n  spec = Multiply()([feats_new, mask_spec(x1)])   \n  \n  # Generating spatial attention mask  and spatially highlighting HSI features\n  spat = Multiply()([feats_new, mask_spat(x2)]) \n\n  # Concatenationg highlighted features and input features  \n  conc = Concatenate(axis = 3)([x1,x2,spec,spat]) \n\n  feats2 = main2(conc)                            # Modality features extraction\n  mask2 = att2(conc)                              # Modality attention mask\n\n  # Highlighting modality features using modality attention mask\n\n  at_feats = Multiply()([feats2, mask2])  \n\n  clsf = clf(at_feats, 15)                        # Classifier with number of classes = 15\n\n  # Initialising model\n  model_att = Model([x1,x2], clsf, name = 'att_clf')\n\n  # Adam with Nesterov Momentum optimizer\n  optim = keras.optimizers.Nadam(0.00002, beta_1=0.9, beta_2=0.999)\n  \n  # Compiling the model\n  model_att.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n\n  for epoch in range(5):  # Number of epochs = 1000\n    \n    model_att.fit(x = [train_hsi, train_lidar], \n                  y = my_ohc(np.expand_dims(train_labels, axis = 1)),\n                  epochs=1, batch_size = 64, verbose = 1)\n    \n    preds2 = model_att.predict([test_hsi, test_lidar], verbose = 1)\n\n    conf = confusion_matrix(test_labels, np.argmax(preds2,1)) # Test set predictions\n    ovr_acc, _, _, _, _ = accuracies(conf)\n\n    if ovr_acc>=k:\n\n      # Saving model for maximum accuracy     \n      model_att.save('/kaggle/working/Houston/models/model')\n      k = ovr_acc\n      ep = epoch\n    print('acc_max_val = ', np.round(100*k,2), '% at epoch', ep) # Maximum test accuracy\n\n\n# Evaluating the model on test set\n\nK.clear_session()\ng = tf.Graph()\n\nwith g.as_default():\n\n  # Loading saved model\n  model = keras.models.load_model('/kaggle/working/Houston/models/model')\n\n  preds_final = model.predict([test_hsi, test_lidar], verbose = 1)\n  conf_final = confusion_matrix(test_labels, np.argmax(preds_final,1))\n  ovr_acc_final, usr_acc, prod_acc, kappa, s_sqr = accuracies(conf_final)\n\nprint('Test accuracy is ', np.round(100*ovr_acc_final,2), '%') # Final test accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Used two Atrous Spatial Pyramid Pooling (ASPP)layers with dilation rates of 12 and 18","metadata":{}},{"cell_type":"code","source":"# Import all the necessary libraries and classes\n\nimport numpy as np\nimport tensorflow as tf\nkeras = tf.keras\nfrom keras import backend as K\nfrom keras.layers import Input\nfrom keras.layers import Conv2D, Reshape, BatchNormalization\nfrom keras.layers import Concatenate\nfrom keras.layers import Multiply, GlobalAveragePooling2D, MaxPooling2D\nfrom keras.models import Model\nfrom sklearn.metrics import confusion_matrix\nfrom keras import regularizers\n\n# Function to perform one hot encoding of the class labels \n\ndef my_ohc(lab_arr):\n    lab_arr_unique =  np.unique(lab_arr)\n    r,c = lab_arr.shape\n    r_u  = lab_arr_unique.shape\n    \n    one_hot_enc = np.zeros((r,r_u[0]), dtype = 'float')\n    \n    for i in range(r):\n        for j in range(r_u[0]):\n            if lab_arr[i,0] == lab_arr_unique[j]:\n                one_hot_enc[i,j] = 1\n    \n    return one_hot_enc\n\n# Function that takes the confusion matrix as input and\n# calculates the overall accuracy, producer's accuracy, user's accuracy,\n# Cohen's kappa coefficient and syandard deviation of \n# Cohen's kappa coefficient\n\ndef accuracies(cm):\n  import numpy as np\n  num_class = np.shape(cm)[0]\n  n = np.sum(cm)\n\n  P = cm/n\n  ovr_acc = np.trace(P)\n\n  p_plus_j = np.sum(P, axis = 0)\n  p_i_plus = np.sum(P, axis = 1)\n\n  usr_acc = np.diagonal(P)/p_i_plus\n  prod_acc = np.diagonal(P)/p_plus_j\n\n  theta1 = np.trace(P)\n  theta2 = np.sum(p_plus_j*p_i_plus)\n  theta3 = np.sum(np.diagonal(P)*(p_plus_j + p_i_plus))\n  theta4 = 0\n  for i in range(num_class):\n    for j in range(num_class):\n      theta4 = theta4+P[i,j]*(p_plus_j[i]+p_i_plus[j])**2\n\n  kappa = (theta1-theta2)/(1-theta2)\n\n  t1 = theta1*(1-theta1)/(1-theta2)**2\n  t2 = 2*(1-theta1)*(2*theta1*theta2-theta3)/(1-theta2)**3\n  t3 = ((1-theta1)**2)*(theta4 - 4*theta2**2)/(1-theta2)**4\n\n  s_sqr = (t1+t2+t3)/n\n\n  return ovr_acc, usr_acc, prod_acc, kappa, s_sqr\n\n# This is the main feature extractor for the hyperpsectral images. \n# The input is a hyperspectral patch. It consists of 6 sets of \n# convolutional, relu and batch normalization operations \n\n\ndef hs(x):\n    conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name='conv31')(x)\n    conv1 = BatchNormalization()(conv1)\n\n    conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(2, 2), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv32')(conv1)\n    conv2 = BatchNormalization()(conv2) \n\n    conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(4, 4), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv33')(conv2) \n    conv3 = BatchNormalization()(conv3)\n                           \n    conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(6, 6), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv34')(conv3) \n    conv4 = BatchNormalization()(conv4)\n\n    conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(8, 8), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv35')(conv4) \n    conv5 = BatchNormalization()(conv5)\n\n    # ASPP module with different dilation rates\n    aspp1 = Conv2D(256, (3, 3), padding='same', dilation_rate=12, activation='relu', name='aspp1')(conv5)\n    aspp2 = Conv2D(256, (3, 3), padding='same', dilation_rate=18, activation='relu', name='aspp2')(conv5)\n\n    # Concatenate the ASPP outputs\n    concat = Concatenate()([aspp1, aspp2])\n\n    # 1x1 convolution to fuse the features\n    fused = Conv2D(256, (1, 1), padding='same', activation='relu', name='fused')(concat)\n\n    conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name='conv36')(fused) \n\n    conv6 = BatchNormalization()(conv6)\n\n    return conv6\n\n# This is the spectral attention mask for hyperspecral images.\n# The input are hyperspectral patches and output is an attention vector \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block and 2D maxpool operation after second and fourth \n# convolution layers. Last convolution layer is followed by a maxpool and \n# Global average pool operation.\n\ndef mask_spec(x):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convc1')(x)\n\n  conv1 = BatchNormalization(name = 'BNc1')(conv1)\n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01),  name = 'convc2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNc2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n  \n  mp1 = MaxPooling2D(pool_size=(2, 2), padding='valid')(res1)\n\n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc3')(mp1) \n\n  conv3 = BatchNormalization(name = 'BNc3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNc4')(conv4)\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n  \n  mp2 = MaxPooling2D(pool_size=(2, 2), padding='valid')(res2)\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc5')(mp2) \n\n  conv5 = BatchNormalization(name = 'BNc5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convc6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BNc6')(conv6)\n\n  mp3 = MaxPooling2D(pool_size=(2, 2), padding='valid')(conv6)\n  gap1 = GlobalAveragePooling2D()(mp3)\n\n  return gap1\n\n# This is the spatial attention mask for hyperspecral images.\n# The input are lidar patches and output is an attention tensor \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block after second and fourth \n# convolution layers. \n\ndef mask_spat(x):\n  \n  conv1 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convt1')(x)\n\n  conv1 = BatchNormalization(name = 'BNt1')(conv1)\n\n  conv2 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01),  name = 'convt2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNt2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n\n  conv3 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt3')(res1) \n\n  conv3 = BatchNormalization(name = 'BNt3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNt4')(conv4)\n\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt5')(res2) \n\n  conv5 = BatchNormalization(name = 'BNt5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convt6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BNt6')(conv6)\n\n  return conv6\n\n# It is a part of modality attention module.  \n# The input are highlighted spectral and spatial attention features from above modules. \n# It consists of 6 convolutional, relu and batch normalization operations. \n\ndef main2(x):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convm31')(x)\n\n  conv1 = BatchNormalization()(conv1)\n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm32')(conv1)\n\n  conv2 = BatchNormalization()(conv2) \n\n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm33')(conv2) \n\n  conv3 = BatchNormalization()(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm34')(conv3) \n\n  conv4 = BatchNormalization()(conv4)\n  \n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm35')(conv4) \n\n  conv5 = BatchNormalization()(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convm36')(conv5) \n\n  conv6 = BatchNormalization()(conv6)\n\n  return conv6\n\n# This is the attention layer for maodality attention module. \n# The input are highlighted spectral and spatial attention features from above modules. \n# It consists of 6 convolutional, relu and batch normalization operations. \n# There is a residual block after second and fourth \n# convolution layers. \n\ndef att2(x):\n  \n  conv1 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convatt1')(x)\n\n  conv1 = BatchNormalization(name = 'BN2t1')(conv1)\n\n  conv2 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BN2t2')(conv2) \n\n  res1 = Concatenate(axis = 3)([conv1, conv2])\n\n  conv3 = Conv2D(128, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt3')(res1) \n\n  conv3 = BatchNormalization(name = 'BN2t3')(conv3)\n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BN2t4')(conv4)\n\n  res2 = Concatenate(axis = 3)([conv3, conv4])\n\n  conv5 = Conv2D(256, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt5')(res2) \n\n  conv5 = BatchNormalization(name = 'BN2t5')(conv5)\n\n  conv6 = Conv2D(1024, (3,3), strides=(1, 1), padding='same', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convatt6')(conv5) \n\n  conv6 = BatchNormalization(name = 'BN2t6')(conv6)\n\n  return conv6\n\n# This is a classifier function. It is a CNN with 6 layers\n# (convolution + RelU + Batch Normalization). Inputs are \n# Attention assisted enhanced features from modality attention module \n# and number of classes\n\ndef clf(x, num_classes):\n  \n  conv1 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                            activation='relu', use_bias=True,  \n                            kernel_regularizer=regularizers.l2(0.01), name = 'convcl1')(x)\n\n  conv1 = BatchNormalization(name = 'BNcl1')(conv1)\n  \n\n  conv2 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl2')(conv1)\n\n  conv2 = BatchNormalization(name = 'BNcl2')(conv2) \n  \n  \n  conv3 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl3')(conv2) \n\n  conv3 = BatchNormalization(name = 'BNcl3')(conv3)\n  \n                           \n  conv4 = Conv2D(256, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl4')(conv3) \n\n  conv4 = BatchNormalization(name = 'BNcl4')(conv4)\n  \n  conv5 = Conv2D(1024, (3,3), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='relu', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl5')(conv4) \n\n  conv5 = BatchNormalization(name = 'BNcl5')(conv5)\n\n  conv6 = Conv2D(num_classes, (1,1), strides=(1, 1), padding='valid', dilation_rate=(1, 1), \n                              activation='softmax', use_bias=True,  \n                              kernel_regularizer=regularizers.l2(0.01), name = 'convcl6')(conv5) \n  \n\n  return Reshape([num_classes])(conv6)\n\n# reading training and test data\n\ntrain_patches = np.load('/kaggle/working/train_patches.npy')\ntest_patches = np.load('/kaggle/working/test_patches.npy')\n\ntrain_labels = np.load('/kaggle/working/train_labels.npy')\ntest_labels = np.load('/kaggle/working/test_labels.npy')\n\n# Separating HSI and lidar patches from training\n# validation and testing data\n\n#num_hsi_bands = 144\n#num_lidar_bands = 1\n\ntrain_hsi = train_patches[:,:,:,0:144]\ntrain_lidar = np.expand_dims(train_patches[:,:,:,144], axis = 3) # Expanding dimension to preserve shape\n                                                           #since only one band is present\n\ntest_hsi = test_patches[:,:,:,0:144]\ntest_lidar = np.expand_dims(test_patches[:,:,:,144], axis = 3)\n\n## Training module\n\nK.clear_session()\ng = tf.Graph()\n\nk = 0        #k is created to temporarily store the maximum validation accuracy for each epoch\n\nwith g.as_default():\n\n  x1 = Input(shape=(11,11,144), name='inputA')     #num_hsi_bands = 144\n\n  x2 = Input(shape=(11,11,1), name='inputB')      #num_lidar_bands = 1\n\n  feats_new = hs(x1)                              # Main feature extraction\n  print(feats_new)\n\n  # Generating spectral attention mask and spectrally highlighting HSI features\n  spec = Multiply()([feats_new, mask_spec(x1)])   \n  \n  # Generating spatial attention mask  and spatially highlighting HSI features\n  spat = Multiply()([feats_new, mask_spat(x2)]) \n\n  # Concatenationg highlighted features and input features  \n  conc = Concatenate(axis = 3)([x1,x2,spec,spat]) \n\n  feats2 = main2(conc)                            # Modality features extraction\n  mask2 = att2(conc)                              # Modality attention mask\n\n  # Highlighting modality features using modality attention mask\n\n  at_feats = Multiply()([feats2, mask2])  \n\n  clsf = clf(at_feats, 15)                        # Classifier with number of classes = 15\n\n  # Initialising model\n  model_att = Model([x1,x2], clsf, name = 'att_clf')\n\n  # Adam with Nesterov Momentum optimizer\n  optim = keras.optimizers.Nadam(0.00002, beta_1=0.9, beta_2=0.999)\n  \n  # Compiling the model\n  model_att.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n\n  for epoch in range(20):  # Number of epochs = 1000\n    \n    model_att.fit(x = [train_hsi, train_lidar], \n                  y = my_ohc(np.expand_dims(train_labels, axis = 1)),\n                  epochs=1, batch_size = 64, verbose = 1)\n    \n    preds2 = model_att.predict([test_hsi, test_lidar], verbose = 1)\n\n    conf = confusion_matrix(test_labels, np.argmax(preds2,1)) # Test set predictions\n    ovr_acc, _, _, _, _ = accuracies(conf)\n    print(\"epoch\",epoch, \"ovr_acc\",ovr_acc)\n\n    if ovr_acc>=k:\n\n      # Saving model for maximum accuracy     \n      model_att.save('/kaggle/working/Houston/models/model')\n      k = ovr_acc\n      ep = epoch\n    print('acc_max_val = ', np.round(100*k,2), '% at epoch', ep) # Maximum test accuracy\n\n\n# Evaluating the model on test set\nprint(\"testing starts\",\"k\",k,\"ovr_acc\",ovr_acc)\n\nK.clear_session()\ng = tf.Graph()\n\nwith g.as_default():\n\n  # Loading saved model\n  model = keras.models.load_model('/kaggle/working/Houston/models/model')\n\n  preds_final = model.predict([test_hsi, test_lidar], verbose = 1)\n  conf_final = confusion_matrix(test_labels, np.argmax(preds_final,1))\n  ovr_acc_final, usr_acc, prod_acc, kappa, s_sqr = accuracies(conf_final)\n\nprint('Test accuracy is ', np.round(100*ovr_acc_final,2), '%') # Final test accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}